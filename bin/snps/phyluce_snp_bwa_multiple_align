#!/usr/bin/env python
# encoding: utf-8
"""
File: snps.py
Author: Brant Faircloth

Created by Brant Faircloth on 29 July 2013 16:07 PDT (-0700)
Copyright (c) 2013 Brant C. Faircloth. All rights reserved.

Description:

"""


import os
import argparse
import ConfigParser

from phyluce import bwa
from phyluce import picard
from phyluce import samtools

from phyluce.log import setup_logging
from phyluce.helpers import FullPaths, CreateDir, is_dir, is_file
from phyluce.raw_reads import get_input_files


import pdb


def get_args():
    """Get arguments from CLI"""
    parser = argparse.ArgumentParser(
        description="""Call SNPs from multiple samples across a sample-specific reference"""
    )
    parser.add_argument(
        "--config",
        required=True,
        type=is_file,
        action=FullPaths,
        default=None,
        help="""A configuration file containing the reference-to-read sample mapping and some metadata"""
    )
    parser.add_argument(
        "--output",
        required=True,
        action=CreateDir,
        default=None,
        help="""The directory in which to store the SNPs files"""
    )
    parser.add_argument(
        "--subfolder",
        type=str,
        default='',
        help="""A subdirectory, below the level of the group, containing the reads"""
    )
    parser.add_argument(
        "--cores",
        type=int,
        default=1,
        help="""The number of compute cores/threads to use"""
    )
    parser.add_argument(
        "--verbosity",
        type=str,
        choices=["INFO", "WARN", "CRITICAL"],
        default="INFO",
        help="""The logging level to use"""
    )
    parser.add_argument(
        "--log-path",
        action=FullPaths,
        type=is_dir,
        default=None,
        help="""The path to a directory to hold logs."""
    )
    parser.add_argument(
        "--no-remove-duplicates",
        action="store_true",
        default=False,
        help="""Do not remove duplicate reads.""",
    )
    parser.add_argument(
        "--mem",
        action="store_true",
        default=False,
        help="""Use bwa mem.""",
    )
    return parser.parse_args()


def get_input_data(log, conf, output):
    # get reference sequence
    references = conf.items('references')
    # ensure there is >1 reference and it is a file
    assert len(references) > 1, "This is the BWA multiple align code. You should have > 1 reference."
    for reference in references:
        try:
            assert os.path.isfile(reference[1])
        except:
            raise IOError("{} is not a file".format(reference))
        # check reference to ensure that bwa has indexed
        for suffix in ['amb', 'ann', 'bwt', 'pac',  'sa']:
            bwa_file = "{}.{}".format(reference[1], suffix)
            try:
                assert os.path.isfile(bwa_file)
            except:
                log.info("Need to create BWA index file for reference")
                bwa.create_index_files(log, reference[1])
    individuals = conf.items('individuals')
    for sample in individuals:
        try:
            assert os.path.isdir(sample[1])
        except:
            raise IOError("{} is not a directory".format(sample[1]))
    both = [dict(references), dict(individuals)]
    references_individuals = {}
    for k in both[0].iterkeys():
        references_individuals[k] = tuple(references_individuals[k] for references_individuals in both)
    return references_individuals


def main():
    # get args and options
    args = get_args()
    # setup logging
    log, my_name = setup_logging(args)
    text = " Starting {} ".format(my_name)
    log.info(text.center(65, "="))
    # get the config file data
    conf = ConfigParser.ConfigParser()
    conf.optionxform = str
    conf.read(args.config)
    # get the input data
    log.info("Getting input filenames and creating output directories")
    references_individuals = get_input_data(log, conf, args.output)
    flowcells = dict(conf.items("flowcell"))
    if args.mem:
        log.info("You are running BWA-MEM")
    for sample, data in references_individuals.iteritems():
        bam, bam_se = False, False
        reference, dir = data
        # pretty print taxon status
        text = " Processing {} ".format(sample)
        log.info(text.center(65, "-"))
        # make a directory for sample-specific assemblies
        sample_dir = os.path.join(args.output, sample)
        os.makedirs(sample_dir)
        # determine how many files we're dealing with
        fastq = get_input_files(dir, args.subfolder, log)
        if fastq.r1 and fastq.r2:
            # bwa align r1 and r2
            if args.mem:
                bam = bwa.mem_pe_align(log, sample, sample_dir, reference, args.cores, fastq.r1, fastq.r2)
            else:
                bam = bwa.pe_align(log, sample, sample_dir, reference, args.cores, fastq.r1, fastq.r2)
            # clean the bam up (MAPq 0 and trim overlapping reads)
            bam = picard.clean_up_bam(log, sample, sample_dir, bam, "pe")
            # get flowcell id
            fc = flowcells[sample]
            bam = picard.add_rg_header_info(log, sample, sample_dir, fc, bam, "pe")
            if not args.no_remove_duplicates:
                bam = picard.mark_duplicates(log, sample, sample_dir, bam, "pe")
            else:
                log.info("You have selected to keep apparent duplicate reads")
        if fastq.singleton:
            # bwa align singleton reads
            if args.mem:
                bam_se = bwa.mem_se_align(log, sample, sample_dir, reference, args.cores, fastq.singleton)
            else:
                bam_se = bwa.se_align(log, sample, sample_dir, reference, args.cores, fastq.singleton)
            # clean the bam up (MAPq 0 and trim overlapping reads)
            bam_se = picard.clean_up_bam(log, sample, sample_dir, bam_se, "se")
            # get flowcell id
            fc = flowcells[sample]
            bam_se = picard.add_rg_header_info(log, sample, sample_dir, fc, bam_se, "se")
            if not args.no_remove_duplicates:
                bam_se = picard.mark_duplicates(log, sample, sample_dir, bam_se, "se")
            else:
                log.info("You have selected to keep apparent duplicate reads")
        if bam and bam_se:
            bam = picard.merge_two_bams(log, sample, sample_dir, bam, bam_se)
        elif bam_se and not bam:
            bam = bam_se
        if not bam:
            raise IOError("There is no BAM file.  Check bwa log files for problems.")
        samtools.index(log, sample, sample_dir, bam)
    # end
    text = " Completed {} ".format(my_name)
    log.info(text.center(65, "="))

if __name__ == '__main__':
    main()
