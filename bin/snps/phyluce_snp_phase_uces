#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
(c) 2015 Tobias Hofmann (tobiashofmann@gmx.net) and Brant Faircloth (brant@faircloth-lab.org)
All rights reserved.

This code is distributed under a 3-clause BSD license. Please see
LICENSE.txt for more information.

Created on 28 December 2015 12:55 CST (-0600)
"""


import os
import sys
import string
import argparse
import ConfigParser

from itertools import izip

from Bio import SeqIO
from Bio.Seq import Seq
from Bio.Alphabet.IUPAC import IUPACAmbiguousDNA

from phyluce import samtools
from phyluce import seqtk
from phyluce.log import setup_logging
from phyluce.helpers import FullPaths, CreateDir, is_dir, is_file

import pdb


def get_args():
    parser = argparse.ArgumentParser(
        description="Phase reads in a BAM file into two separate alleles. Then produce a consensus sequence for each allele.",
    )
    parser.add_argument(
        "--config",
        required=True,
        type=is_file,
        action=FullPaths,
        default=None,
        help="""A configuration file containing the reference-to-read sample mapping and some metadata"""
    )
    parser.add_argument(
        "--bams",
        required=True,
        type=is_dir,
        action=FullPaths,
        default=None,
        help="""The directory containing sample-specific BAM files"""
    )
    parser.add_argument(
        "--output",
        required=True,
        action=CreateDir,
        default=None,
        help="""The directory in which to store the SNPs files"""
    )
    parser.add_argument(
        '--conservative',
        action='store_true',
        default=False,
        help='Use this flag if you want to discard all base calls with limited certainty (covered by <3 reads). This will produce the ambiguity character "N" instead of that potential base call in the final sequence.'
    )
    parser.add_argument(
        '--cores',
        type=int,
        default=1,
        help='For parallel processing you can choose the number of cores you want CLC to run on.'
    )
    parser.add_argument(
        "--verbosity",
        type=str,
        choices=["INFO", "WARN", "CRITICAL"],
        default="INFO",
        help="""The logging level to use"""
    )
    parser.add_argument(
        "--log-path",
        action=FullPaths,
        type=is_dir,
        default=None,
        help="""The path to a directory to hold logs."""
    )
    return parser.parse_args()


def phase_bam(log, sample, reference, bam, output_dir):
    phasing_out_dir = os.path.join(output_dir, sample)
    # phase
    allele_0_file, allele_1_file = samtools.phase(log, sample, phasing_out_dir, bam)
    # sort phased BAMs
    sort_phased_0 = samtools.sort(log, sample, phasing_out_dir, allele_0_file)
    sort_phased_1 = samtools.sort(log, sample, phasing_out_dir, allele_1_file)
    # call alleles
    make_cons_0 = samtools.call(log, sample, phasing_out_dir, reference, sort_phased_0, "0")
    make_cons_1 = samtools.call(log, sample, phasing_out_dir, reference, sort_phased_1, "1")
    make_cons_unphased = samtools.call(log, sample, phasing_out_dir, reference, bam, "unphased")
    # convert to fasta
    fasta_cons_0 = seqtk.fq_to_fa(log, sample, phasing_out_dir, make_cons_0, "0")
    fasta_cons_1 = seqtk.fq_to_fa(log, sample, phasing_out_dir, make_cons_1, "1")
    fasta_cons_unphased = seqtk.fq_to_fa(log, sample, phasing_out_dir, make_cons_unphased, "unphased")
    # TODO: if we want to cleanup, add here
    return fasta_cons_0, fasta_cons_1, fasta_cons_unphased


def clean_fastas(log, fastas, output_dir, conservative=True):
    log.info("Checking for correct FASTA files")
    # check to make sure we have all the appropriate fasta files
    for fasta in fastas:
        try:
            assert os.path.isfile(fasta)
        except:
            raise IOError("Not all FASTA files were created.")
    # conver degen bases to N
    translation_table1 = string.maketrans("ywrksmYWRKSM", "NNNNNNNNNNNN")
    # convert lowercase/low qual bases to N
    translation_table2 = string.maketrans("actgn", "NNNNN")
    clean_fastas = []
    contigs = {0:set(), 1:set()}
    log.info("Cleaning FASTA files")
    for fasta in fastas:
        outfile_name = os.path.splitext(fasta)[0] + ".clean.fasta"
        clean_fastas.append(outfile_name)
        with open(fasta, "rU") as infile:
            with open(outfile_name, "w") as outfile:
                for record in SeqIO.parse(infile, "fasta"):
                    # cleanup sequence
                    s = str(record.seq)
                    s = s.translate(translation_table1)
                    if conservative:
                        # translate lowercase sequence to N
                        s = s.translate(translation_table2)
                    else:
                        # uppercase everything
                        s = s.upper()
                    record.seq = Seq(s, IUPACAmbiguousDNA())
                    #TODO: REMOVE N-only sequences (??)
                    # clean/rename header
                    if fasta.endswith(".0.fasta"):
                        # we're tracking contig names to make sure each file
                        # eventually contains both alleles for all loci
                        contigs[0].add(record.id)
                    elif fasta.endswith(".1.fasta"):
                        # we're tracking contig names to make sure each file
                        # eventually contains both alleles for all loci
                        contigs[1].add(record.id)
                    outfile.write(record.format("fasta"))
    # now that we've cleaned sequences and now which loci are in each allele
    # file, output the balanced alleles to their files.
    log.info("Balancing FASTA files")
    balanced_contigs = contigs[0].intersection(contigs[1])
    balanced_fastas = []
    for fasta in clean_fastas:
        outfile_name = os.path.splitext(fasta)[0] + ".balanced.fasta"
        balanced_fastas.append(outfile_name)
        with open(fasta, "rU") as infile:
            with open(outfile_name, "w") as outfile:
                for record in SeqIO.parse(infile, "fasta"):
                    if record.id in balanced_contigs:
                        # clean/rename header
                        if fasta.endswith(".0.clean.fasta"):
                            record.id = "{0}_0 |{1}_phased".format(record.id, record.id.split("_")[0])
                        elif fasta.endswith(".1.clean.fasta"):
                            record.id = "{0}_1 |{1}_phased".format(record.id, record.id.split("_")[0])
                        elif fasta.endswith(".unphased.fasta"):
                            record.id = "{0} |{1}_hom".format(record.id, record.id.split("_")[0])
                        record.name = ""
                        record.description = ""
                        outfile.write(record.format("fasta"))
                    else:
                        if fasta.endswith(".unphased.clean.fasta"):
                            record.id = "{0} |{1}_hom".format(record.id, record.id.split("_")[0])
                            record.name = ""
                            record.description = ""
                            outfile.write(record.format("fasta"))
                        else:
                            pass
    log.info("Symlinking FASTA files")
    # symlink fastas into a new directory
    balanced_fastas_dir = os.path.join(output_dir, "fastas")
    if not os.path.isdir(balanced_fastas_dir):
        os.makedirs(balanced_fastas_dir)
    else:
        pass
    balanced_fastas_links = []
    for balanced_fasta in balanced_fastas:
        balanced_fasta_link = os.path.join(balanced_fastas_dir, os.path.basename(balanced_fasta))
        balanced_fastas_links.append(balanced_fasta_link)
        os.symlink(balanced_fasta, balanced_fasta_link)
    return balanced_fastas_dir, balanced_fastas_links


def join_files(log, balanced_fastas_dir, to_join):
    text = " Merging alleles from all loci"
    log.info(text.center(65, "-"))
    outfile_name = os.path.join(balanced_fastas_dir, "joined_allele_sequences_all_samples.fasta")
    with open(outfile_name, "w") as outfile:
        for f1, f2 in to_join:
            fa=SeqIO.parse(open(f1), "fasta")
            fb=SeqIO.parse(open(f2), "fasta")
            # this joins alleles one-after-the-other (interleaved) versus
            # tobi's original code that just appened the .1. alleles following the .0.
            # alelles
            # NOTE: tobi's old code just cat-ed allele 1 after allele 0.
            cnt = 0
            for allele_0, allele_1 in izip(fa, fb):
                try:
                    cnt += 1
                    assert allele_0.description.split("|")[1] == allele_1.description.split("|")[1]
                    outfile.write(allele_0.format("fasta"))
                    outfile.write(allele_1.format("fasta"))
                except:
                    raise IOError("Allele files appear to be unbalanced.")
                    sys.exit()
            log.info("Wrote {} loci for {}".format(cnt, os.path.basename(f1).split('.')[0]))


def get_input_data(log, conf, bams, output):
    # get reference sequence
    references = conf.items('references')
    # ensure there is >1 reference and it is a file
    assert len(references) > 1, "This is the BWA multiple align code. You should have > 1 reference."
    for reference in references:
        try:
            assert os.path.isfile(reference[1])
        except:
            raise IOError("{} is not a file".format(reference))
    individuals = conf.items('individuals')
    all_bams = []
    for sample in individuals:
        try:
            bam_name = "{}-CL-RG-MD-M.bam".format(sample[0])
            bam = os.path.join(bams, sample[0], bam_name)
            assert os.path.isfile(bam), "BAM {} not found".format(bam_name)
            all_bams.append((sample[0], bam),)
        except AssertionError:
            bam_name = "{}-CL-RG-MD.bam".format(sample[0])
            bam = os.path.join(bams, sample[0], bam_name)
            assert os.path.isfile(bam), "BAM {} not found".format(bam_name)
            all_bams.append((sample[0], bam),)
    both = [dict(references), dict(all_bams)]
    references_bams = {}
    for k in both[0].iterkeys():
        references_bams[k] = tuple(references_bams[k] for references_bams in both)
    return references_bams


def main():
    # get args and options
    args = get_args()
    # setup logging
    log, my_name = setup_logging(args)
    text = " Starting {} ".format(my_name)
    log.info(text.center(65, "="))
    # get the config file data
    conf = ConfigParser.ConfigParser()
    conf.optionxform = str
    conf.read(args.config)
    # get the input data
    log.info("Getting input filenames and creating output directories")
    references_bams = get_input_data(log, conf, args.bams, args.output)
    to_join = []
    for individual, data in references_bams.iteritems():
        text = " Processing {} ".format(individual)
        log.info(text.center(65, "-"))
        reference, bam = data
        fastas = phase_bam(log, individual, reference, bam, args.output)
        balanced_fastas_dir, balanced_fastas = clean_fastas(log, fastas, args.output, args.conservative)
        # this is sort of stupid, but we need to make abs. sure we have the
        # correct files.
        for fasta in balanced_fastas:
            if fasta.endswith("0.clean.balanced.fasta"):
                allele_0 = fasta
            elif fasta.endswith("1.clean.balanced.fasta"):
                allele_1 = fasta
        to_join.append((allele_0, allele_1))
    # interleave those puppies
    join_files(log, balanced_fastas_dir, to_join)
    # end
    text = " Completed {} ".format(my_name)
    log.info(text.center(65, "="))


if __name__ == '__main__':
    main()
